**Проект спринта "Обучение с учителем"**

**Тема "Отток клиентов банка"**

**Описание проекта**

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Необходимо спрогнозировать, уйдёт клиент из банка в ближайшее время или нет.

Имеются исторические данные о поведении клиентов и расторжении договоров с банком.<br>
Необходимо построить модель с предельно большим значением F1-меры (нужно довести метрику до 0.59).<br>
Для оценки качества модели следует проверить F1-меру на тестовой выборке.<br>
Дополнительно измерить AUC-ROC, сравнивая её значение с F1-мерой.

**Цели и задачи проекта**

Цели проекта:<br>
получить практические навыки построения и настройки модели для задачи классификации, ее проверки на тестовой выборке.

Задачи проекта:<br>
построить модель для задачи классификации, которая спрогнозирует отток клиентов банка в ближайшее время;<br>
настроить модель с учетом метрики F1-мера (довести долю правильных ответов по крайней мере до 0.59);<br>
проверить метрику F1-мера на тестовой выборке;<br>
измерить AUC-ROC, сравнивая её значение с F1-мерой.

**Содержание проекта**
1. Загрузка файла с данными и изучение общей информации<br>
Шаг 1.1. Загрузка файла<br>
Шаг 1.2. Изучение данных<br>
Шаг 1.3. Предобработка данных<br>
Шаг 1.4. Проверка количественных значений<br>
Шаг 1.5. Изучение категориальных значений<br>

2. Разбивка данных на выборки<br>
Шаг 2.1. One-hot кодирование<br>
Шаг 2.2. Разбивка данных<br>
Шаг 2.3. Масштабирование признаков<br>

3. Построение моделей для задач классификации (без учета дисбаланса)<br>
Шаг 3. Построение моделей<br>

3.1. Алгоритм "Дерево решений"<br>
3.2. Алгоритм "Случайный лес"<br>
3.3. Алгоритм "Логистическая регрессия"<br>

4. Борьба с дисбалансом<br>
Шаг 4.1. Взвешивание классов<br>
Шаг 4.2. Увеличение выборки (Upsampling)<br>
Шаг 4.3. Уменьшение выборки (Downsampling)<br>

5. Построение ROC-кривой и AUC-ROC лучшей модели<br>
Шаг 5. Построение ROC-кривой<br>

6. Проверка модели на тестовой выборке<br>
Шаг 6.1. Проверка модели на тестовой выборке<br>
Шаг 6.2. Сравнение качества предсказаний с константной моделью<br>

7. Общий вывод по проекту<br>
Шаг 7. Общий вывод<br>

**Вывод по проекту**

**Предварительное изучение данных:**<br>
-в датафрейме 10000 записей, 14 полей;<br>
-при предварительном изучении данных был выявлен ряд проблем, таких как пропущенные значения в поле Tenure, наличие полей, RowNumber, CustomerId, Surname, не вносящих смысловой нагрузки в модель, наличие полей, для которых виделось возможным изменения типа данных, замены классификации более краткими обозначениями для снижения нагрузки и удобства визуализации данных. В ходе обработки данных проблемы устранены;<br>
-доля выбросов по каждому признаку в выборке не превышает 3%; данные выбросы выглядят вполне реалистично, их можно отнести к контекстным выбросам;
-исходя из особенностей выборки данные оставили без изменений (выбросы не удалены);<br>
-некорректные значения в полях, содержащих категориальные значения, отсутствуют;<br>
-каждый год наблюдается незначительный прирост клиентов банка, имеется существенная необходимость в удержании старых клиентов;<br>
-количество активных и неактивных клиентов банка отличается незначительно. Требуется уточнение у маркетологов, что подразумевается под активностью;<br>
-за период, соответствующий выборке, с банком прекратили сотрудничество 20% клиентов;<br>
-доля клиентов, использующих более 3 продуктов банка - 3.26%. Доля клиентов, использующих только 1 продукт и прекративших сотрудничество с банком - 14%. Следует пересмотреть продуктовую линию.

**Разбивка данных на выборки:**<br>
-выполнено one-hot кодирование категориальные признаков в выборке;<br>
-масштабирование количественных признаков;<br>
-в выборке выделены признаки (features) и целевой признак (target);<br>
-изучен целевой признак на сбалансированность, соотношение классов 1:4, признак не сбалансирован;<br>
-данные разбиты на три набора (обучающий, валидационный, тестовый) в пропорции 3:1:1 соответственно.

**Построение моделей для задач классификации:**<br>
-проанализировано три алгоритма решения задач классификации: 'DecisionTreeClassifier', 'RandomForestClassifier', 'LogisticRegression';<br>
-каждая из моделей была обучена для нескольких сочетаний гиперпараметров как без учета дисбаланса, так и с учетом дисбаланса (методы борьбы с дисбалансом классов: взвешивание классов, upsampling, downsampling);<br>
-критериями проверки качества моделей были выбраны параметры accuracy, F1-мера, ROC-AUC;<br>
-для каждой вариации обучения моделей были рассчитаны указанные параметры с последующим выбором наилучшего показателя;<br>
-наилучшая F1-мера была достигнута для модели случайного леса с гиперпараметрами: criterion='gini', n_estimators=25, max_depth=12, min_samples_leaf=6, class_weight='balanced';<br>
-полученные значения F1-меры: на валидационном наборе - 0.65, на тестовом наборе - 0.63, что удовлетворяет условиям поставленной задачи;<br>
-дополнительно была построена ROC-кривая и рассчитана метрика AUC-ROC лучшей модели;<br>
-выполнена проверка на адекватность итоговой модели с помощью константной модели DummyClassifier.
